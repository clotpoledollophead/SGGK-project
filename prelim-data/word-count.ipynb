{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clotpoledollophead/SGGK-project/blob/main/middle_english_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9JWO0UkQHwCI",
        "outputId": "fb50deb5-c00c-4139-ad3e-773744d3ef3d"
      },
      "outputs": [],
      "source": [
        "%pip install cltk  # analyzes historical and classical texts, including Middle English\n",
        "%pip install nltk \n",
        "%pip install spacy  # advanced text processing (can be customized for Middle English).\n",
        "%pip install unidecode  # normalizing text by converting non-standard characters to their closest ASCII equivalents\n",
        "%pip install gensim  # topic modeling, text similarity analysis, and other advanced linguistic tasks\n",
        "%pip install scikit-learn\n",
        "%pip install matplotlib seaborn\n",
        "%pip install pandas\n",
        "%pip install pytesseract  # enabling digitization of scanned texts (OCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ue3M6r2nK44t"
      },
      "outputs": [],
      "source": [
        "import cltk\n",
        "import nltk\n",
        "import spacy as sp\n",
        "import unidecode as ud\n",
        "import gensim as gm\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import pytesseract as pt\n",
        "from collections import Counter\n",
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "Cei3c45EyrB6",
        "outputId": "e8efa197-ebad-4649-ca1b-3b436e679157"
      },
      "outputs": [],
      "source": [
        "text_files = [\"corpus/passus-i-sggk.txt\", \"corpus/passus-ii-sggk.txt\", \"corpus/passus-iii-sggk.txt\", \"corpus/passus-iv-sggk.txt\"]\n",
        "STOPWORDS_URL = \"https://raw.githubusercontent.com/cltk/cltk/master/src/cltk/stops/enm.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_stopwords(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    content = response.text\n",
        "\n",
        "    start_marker = \"STOPS: list[str] = [\"\n",
        "    start_idx = content.index(start_marker) + len(start_marker)\n",
        "    end_idx = content.index(\"]\", start_idx)\n",
        "    stopwords_content = content[start_idx:end_idx].strip()\n",
        "\n",
        "    stopwords = [\n",
        "        word.strip().strip('\"')\n",
        "        for word in stopwords_content.split(\",\")\n",
        "        if word.strip()\n",
        "    ]\n",
        "    return stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_file(filepath, stopwords):\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read().lower()\n",
        "\n",
        "    tokens = text.split()\n",
        "\n",
        "    word_counts_with_stopwords = Counter(tokens)\n",
        "\n",
        "    tokens_no_stops = [word for word in tokens if word not in stopwords]\n",
        "    word_counts_without_stopwords = Counter(tokens_no_stops)\n",
        "\n",
        "    return word_counts_with_stopwords, word_counts_without_stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_dataframe(counter):\n",
        "    df = pd.DataFrame(counter.items(), columns = ['Word', 'Count'])\n",
        "    df.sort_values(by = 'Count', ascending = False, inplace = True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetched 275 stop words.\n",
            "Processing: corpus/passus-i-sggk.txt\n",
            "Processing: corpus/passus-ii-sggk.txt\n",
            "Processing: corpus/passus-iii-sggk.txt\n",
            "Processing: corpus/passus-iv-sggk.txt\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>watz</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>ful</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>bot</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>so</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>ȝe</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2947</th>\n",
              "      <td>fynde.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>þer-vnder</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2949</th>\n",
              "      <td>negh</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2950</th>\n",
              "      <td>inwyth</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5709</th>\n",
              "      <td>pence.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5710 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Word  Count\n",
              "3          watz    180\n",
              "64          ful    150\n",
              "107         bot    112\n",
              "152          so    110\n",
              "132          ȝe     88\n",
              "...         ...    ...\n",
              "2947     fynde.      1\n",
              "682   þer-vnder      1\n",
              "2949       negh      1\n",
              "2950     inwyth      1\n",
              "5709     pence.      1\n",
              "\n",
              "[5710 rows x 2 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords = fetch_stopwords(STOPWORDS_URL)\n",
        "print(f\"Fetched {len(stopwords)} stop words.\")\n",
        "\n",
        "total_with_stopwords = Counter()\n",
        "total_without_stopwords = Counter()\n",
        "\n",
        "dfs_with_stopwords = {}\n",
        "dfs_without_stopwords = {}\n",
        "\n",
        "for filepath in text_files:\n",
        "    print(f\"Processing: {filepath}\")\n",
        "    counts_with, counts_without = process_file(filepath, stopwords)\n",
        "    \n",
        "    total_with_stopwords.update(counts_with)\n",
        "    total_without_stopwords.update(counts_without)\n",
        "\n",
        "    file_name = os.path.splitext(os.path.basename(filepath))[0]\n",
        "    dfs_with_stopwords[file_name] = to_dataframe(counts_with)\n",
        "    dfs_with_stopwords\n",
        "    dfs_without_stopwords[file_name] = to_dataframe(counts_without)\n",
        "    dfs_without_stopwords\n",
        "\n",
        "total_with_df = to_dataframe(total_with_stopwords)\n",
        "total_without_df = to_dataframe(total_without_stopwords)\n",
        "total_with_df\n",
        "total_without_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPyywW1+aHIlGjYVmg6Tg5i",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
